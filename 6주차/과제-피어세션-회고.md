# 과제 정리
## [필수 과제 1] VGG-11 구현 및 Fine-tuning

scratch code보다 fine tuning의 성능이 더 좋을 것이라 생각했다. 그런데 두 번째 시도까지 loss와 accuracy가 이상해서 봤더니 fine tuning 코드의 optimizer가 잘못 설정되어서 classifier가 학습되지 않았던 것이었다. 그 문제 빼고는 아주 어렵지는 않았다.

과제를 수행하다 차원이 안 맞을 때는 모델 class의 foward 함수에 아래와 같은 코드를 사용하자.

```python
print(f'Tensor shape after convolution layers is {x.shape}')
```

input뿐만 아니라 model을 전달하는 장치가 GPU인지 CPU인지 확인하면서 코드를 짜자.

model.train(), model.eval()이 적절한 위치에 있는지 또한 확인해야 한다.

## [필수 과제 2] Data Augmentation

문제에서 시키는 대로 풀었다. 근데 다양한 데이터 증강을 해도 검증 점수가 큰 차이가 없었다.

## [[필수 과제 3] Classification to Segmentation

오피스아워를 듣고 풀었다.

간단한 코드로 영상분류 문제를 segmentation 문제로 바꿀 수 있다는 것이 신기했다.

이제 영상분류 조금 할 줄 안다고 생각했는데 CV의 길은 아직 멀다...


# 피어세션 정리

CV에서 global average pooling layer 많이 사용

파라미터 개수 : 2 * 3 * 3 * w * h < 1 * 5 * 5 * w * h
- 2 * 3 * 3 => (receptive field - 3 + 1) - 3 + 1 ) = 1
- 5 * 5 => (5 - 5 + 1) = 1
 
합성곱 레이어 통과 후에도 동일한 크기의 출력 사이즈를 얻으려면
- kernel_size // 2 == padding

openAI Clip
- 4억개의 데이터를 이미 학습해서 성능을 향상시킨 모델


# 멘토링 정리
## 팀 구성 및 역할 분담
6명이 팀원이라면  역할을 분명히 나눠야 한다.
- 예: 2명 씩 3조로 나누기 

## 의료분야에서 AI 사용
법적인 제재는 병원데이터는 환자의 개인정보라서 수집이 어렵다. 데이터가 안 모여서 분석이 어렵다. 다른 국가의 데이터를 받아서 하고 있으나 인종별 특징이 다른 점이 고려되지 않았다.

의료 데이터베이스 다루기 힘들다. 환자가 누워있는 시간을 로그로 저장하면 데이터용량이 테라로 넘어갈수도 있다.

진단은 주관적인 요소가 많이 포함된다. 아직은 인공지능은 보조 수단이다. 성능은 나쁘지 않지만 여전히 리스크가 있기 때문이다.
- 예: 코로나 검사를 X-ray 이미지로 검진할 수 있다. 
    - 정확도는 80% => 하지만 활용은 안 한다.


# 오피스아워 정리
```python
import pdb

def main():
    pdb.set_trace() # 터미널에서 디버깅 가능
```

정규화 장점
- 0 주변 값이 많으면 학습에 안정적인 효과를 준다.

PDF 파일에 필기하면서 오피스아워를 다시 듣자.

# 학습 회고

요즘 컴퓨터비전에서 transformer를 많이 사용한다고 해서 NLP 강의도 들었다.

CV 강의는 마크다운으로 학습 정리를 하면서 수강했고 NLP 강의 PDF에 필기만 해서 수강했다.

Data Viz 강의까지 듣느라 힘들었는데 다음주는 시각화 강의가 없으니까 이번주보다는 힘들지 않게 공부할 수 있을 것 같다.