# 1. 이활석 (Upstage) - 서비스 향 AI 모델 개발하기
## 1.1. 학습 데이터셋 준비
- 서비스 개발 시에는 서비스 요구 사항만 있다.
    - 모델을 만들고 수정하기 위해 학습 데이터 종류, 수량, 정답이 지속적으로 추가되어야 한다.
- AI 모델에는 입력과 출력 정답 쌍이 필요하다.
- 학습 데이터셋 준비에는 서비스 기획자, 외주업체, AI 모델 개발자 등 많은 관계자와 커뮤니케이션이 필요하다.

## 1.2. 테스트 데이터셋 / 테스트 방법 준비
- 서비스 품질을 위해 오프라인 테스크 결과를 온라인 테스트 결과와 유사하게 설계해야 한다. 
    - 오프라인 테스트 : 실 서비스 적용 전에 개발 환경에서의 평가
        - 정량 : AI 모델 후보 선택 목적으로 사용
        - 정성 : 후보 AI 모델 분석 후 서비스 출시 버전 선택
    - 온라인 테스트 : 실 서비스 적용 시에 평가
        - 정량 : 서비스 시나리오에서 자동 정량 평가
        - 정성 : VOC를 살펴봐서 AI 모델 개선 포인트 파악

## 1.3. 모델 요구사항 도출
- 오프라인 테스트와 온라인 테스트의 요구사항은 다르다.
- QPS, Queries Per Second : 초당 처리 가능한 요청 수
- Edit Distance (Levenshtein Distance) : 편집 거리 알고리즘
- 요구사항 종류 : 처리 시간, 목표 정확도, 목표 qps, Serving 방식, 장비 사양

## 1.4. AI 서비스 인력
- Data Curator : 학습 데이터 준비(외주 업체 대응, 작업 가이드 문서, QnA 대응), 정량 평가 수립, 정성 평가 분석
- Molder : AI 모델 구조 제안, AI 모델 성능 분석/디버깅
- IDE Developer : 라벨링 툴 개발, 모델 분석 툴 개발, 모델 개발 자동화, 파이프 라인 개발
- Model Engineer : 모델 최적화, 모델 서빙


# 2. 김상훈 (Upstage) - 캐글 그랜드마스터의 경진대회 노하우 대방출
## 2.1. 캐글 대회 목적
- Featured  : 상업적 목적의 예측 대회. 실제 기업에서 우승한 모델을 현업에 적용하기도 함
- Research : 연구 목적의 대회. 연구 목적이라 상금이 낮은 편
- Getting Started & Playground : 초심자를 위한 학습 목적의 대회. 예: 타이타닉 생존자 예측 대회, 랭킹용 포인트나 메달을 얻을 수 없음
- Analytics : 데이터 분석 목적의 대회. 데이터 탐색과 이를 시각화한 노트북을 제출하는 대회
- Recruitment : 리크루팅 목적의 대회

## 2.2. 대회 제출 방식
- General Competition (리소스 제약 없음) : submission.csv 파일만 제출
- Code Competition (리소스 제약 있음) : 캐글 노트북에서 코드를 실행시켜 submission.csv 파일을 생성해야 함, submission.csv을 생성할 때 리소스제한(GPU, CPU, RAM, 실행시간)이 있음, 캐글러들이 쓸모 있는 모델을 만들도록 강제함
- Private LB, Public LB 순위가 뒤섞이는 현상을 Shake-up이라 함

## 2.3. 탄탄한 검증 전략 구축
검증 전략 (Validation Strategy) : Test set에서 얻은 점수와 Training set에서 얻어진 점수 갭을 줄이는 평가 방법

## 2.4. 앙상블
블렌딩: 캐글에선 모델별 예측 값을 섞는 것을 의미. weighted sum의 방법을 많이 사용
함

추천 조합
- 정형 데이터 : LGBM + NN 앙상블
- 텍스트 : LSTM + BERT

## 2.5. 싱글 모델 개선 전략
상위 랭커들이 discussion에 언급한 자신의 싱글모델 점수 참고. 대회 종료가 1~2주 정도 남았을 때 싱글 모델 점수로만 50등 내에 들면 좋음

## 2.6. 코드 관리
v1, v2, v3, ... 순서로 개별 폴더를 만들어 코드 관리, 여러 버전의 모델을 앙상블 하기 위해 버전 별 폴더 추천

## 2.7. 주피터에서 터미널 열기
주피터에서 터미널을 열면 크롬 창을 닫아도 리소스가 살아있어 원격 학습 가능


# 3. 구종만 (Tower Research Capital) - AI + ML과 Quant Trading
- 트레이딩은 보통 3일 정도로 자산을 보유하고 단기적인 가격 변화에서 이득을 본다.
    - 블랙박스 : 100% 자동 매매
    - 그레이박스 : 자동 매매 + 트레이더의 주관
## 3.1. 퀀트 트레이딩의 예
1. arbitrage : 시장 간 가격차이가 발생할 때 시세차익
2. market making : 매수와 매도 주문을 동시에 냄
3. statistical arbitrage : 미래 가격 변화 예측
    - 선형회귀 90% + 머신러닝 5% + 딥러닝 5% 

## 3.2. 퀀트 트레이딩 플레이어들
퀀트 헤지펀드 / 로보 어드바이저
- 고객의 자본(수천억~수십조)을 운영하고 운용자금과 이익의 일부를 보수로 받음
- 상대적으로 긴 보유기간
프랍 트레이딩 (자기 자본 거래)
- 회사 파트너들의 자본(수십~수백억)을 거래
- 규모가 작은 대신 대개 HFT나 market making을 통해 높은 수익률을 추구
- 성공적인 팀은 꾸준히 연간 100% 이상의 수익률을 냄
금융위기 이후 규제 변경으로 은행들은 자기자본 거래를 하지 않음
- 퀀트 기반 트레이딩 서비스를 제공하는 쪽에 초점

## 3.3. 가격 예측에 딥러닝 적용이 어려운 이유
가격 예측 문제를 이미지 인식과 비교하자면?
- 털 한가닥만 보고 고양이인지 개인지 분류해야 함 (신호 변화)
- 고양이들이 분류를 피하기 위해 털 모양을 바꿈 (위장)
- 개와 고양이의 기준을 종종 정부가 바꿈 (규제)

문제가 어려워 오버피팅되기 싶다.

시장이 변화할 때 변화하지 않는 속성과 변화하는 속성을 구분할 수 있으면 선형회귀로도 대부분의 가치를 뽑아낼 수 있다.

# 4. 문지형 (Upstage) - 내가 만든 AI 모델은 합법일까, 불법일까
- 저작권 : “창작성”이 있다면 별도의 등록절차없이 자연히 발생
- MRC(Machine Reading Comprehension) : 기계 독해 
- 합법적으로 데이터 사용하기
    - 저작자와 협의
    - 저작재산권 독점적/비독점적 이용허락
    - 저작재산권 전부/일부에 대한 양도
    - 라이센스 : 저작자가 제안한 특정 조건을 만족하면 이용이
가능하도록 만든 저작물에 대한 이용허락 규약
        - 예: Creative Commons License (CCL)
            - 나무위키 : CC-BY-NC-SA
- 뉴스 기사의 저작권은 언론사에 있으나 한국언론진흥재단에서 대부분 언론사의 저작권을 위탁해서 관리
    - 조선, 중앙, 동아의 기사를 이용하면 언론사에 연락하자.
- KDX의 이용 약관을 자세히 살펴볼 것

# 5. 이준엽 (Upstage) - Full Stack ML Engineer
## 직무 소개
- ML Engineer : 머신러닝, 딥러닝을 이해하고, 연구하고, Product 를 만드는 엔지니어
- Full stack Engineer : Client/Server software 를 개발할 수 있는 사람
- Full stack ML Engineer : Deep learning research를 이해하고 ML Product로 만들 수 있는 Engineer
    - ML Service
    - Edge device service : 예민한 정보(얼굴 사진)는 서버에 저장하지 않고 모바일에서 처리
    - Data collection
## Full stack ML Engineer 장단점
- 장점 : 재미, 다각적인 성장 가능, 팀 플레이에 도움, 빠른 프로토타이핑
- 단점 : 기술 스택에 대한 깊이 얇아짐, 학습에 많은 시간 필요

## ML Product 생성 과정
1. 요구사항 전달 
    - 고객사 미팅(B2B) or 서비스 기획(B2C)
    - 요구사항 + 제약사항 정리
    - ML 문제로 회귀
2. 데이터 수집 : 시간과 비용 큼
    - Raw 데이터 수집 
    - Annotation Tool 기획 및 개발
    - Annotation Guide 작성 및 운용
3. ML 모델 개발
    - 기존 연구 Research 및 내재화
    - 실 데이터 적용 실험 + 평가 및 피드백
    - 모델 차원 경량화 작업
4. 실 서버 배포
    - 엔지니어링 경량화 작업
    - 연구용 코드 수정 작업
    - 모델 버전 관리 및 배포 자동화

## ML Team 구성
### 이상
- 프로젝트 매니저 1명
- 개발자 1명
- 연구자 2명
- 기획자 1명
- 데이터 관리자 1명

### 현실
- PM + 기획자 + 연구자 : 1명
- 개발자 + 연구자 + 데이터 관리자 : 1명
- 개발자 + 데이터 관리자 : 1명

## ML Team에서 Full stack ML Engineer 역할
Full stack ML Engineer : 개발자 + 연구자 + 데이터 관리자
- 역할 1 : 실 생활 문제를 ML문제로 공식화
- 역할 2 : Raw Data 수집
- 역할 3 : Annotation tool 개발
- 역할 4 : Data version 관리 및 loader 개발
- 역할 5 : Model 개발 및 논문 작성
- 역할 6 : Evaluation tool 혹은 Demo 개발
- 역할 7 : 모델 실 서버 배포

## 시작 방법
1. ML 논문 읽고 재현
2. 기술 시현을 할 Web을 만들어보자.
3. 로그인 기능 추가

# 6. 오혜연 (KAIST) - AI Ethics
## AI & Individuals
### 편향된 AI 사례와 원인
1. COMPAS : 흑인 재소자를 백인 재소자보다 재범 확률이 높게 평가함
    - 의도한 결과 아니고 원인 파악하기 어렵다.
2. 편향의 이유
    - 레이블 기준이 편향을 만들기도 한다.
    - 레이블을 선택한 사람들에 의해 편향이 생기기도 한다.
    - 데이터 수집 수단에 따라서 모델이 under-representation될 수도 있다.(수집된 데이터가 모집단을 대표하지 않을 수도 있다.)
    - 적은 표본으로 인해 over-representation이 나타난다.
    - 특성 선택 과정에서 편향이 생긱도 한다.
    - 패턴 생성 때문에 의도하지 않게 모델이 차별하거나 모델러에 의해 의도적인 차별이 생길 수 있다.
    - Metric 때문에 편향이 생기기도 한다.

### 사생활 침해가 될 수 있는 AI 
중앙 서버에 접근할 수 있으면 AI 기술로 저장된 데이터에 접근할 수 있어서 문제가 될 수 있다.
- 해결 방안 : 서버 분산, 비식별화

## AI & Society
- The AI Now Report : AI 기술이 미래에 어떤 문제를 발생시킬 것인지 기록
    - https://ainowinstitute.org/AI_Now_2016_Report.pdf
- AI 기술이 노동 시장에 영향을 미쳐서 사회적 불평등을 촉진한다.
- 언어 모델이 가짜 뉴스를 만들 수도 있다.
- 딥페이크가 사회적 문제가 되고 있다.

## AI & Individuals
- 의료 AI는 인류에 도움이 된다.
    - AI 기술로 건강관리
- AI로 야기되는 환경 문제, AI로 해결하는 환경 문제
    - 대형 모델 하나 학습하는데 에너지 소비가 크다.  
    - 기후 위기에 도움이 되기도 한다.
        - AI 솔루션으로 효율적인 전기 발전과 소비를 가능하게 할 수 있다.
        - AI 기술로 동선을 파악해 도시 계획을 할 수 있다.
    

# 7. 박은정 (Upstage) - AI 시대의 커리어 빌딩
## 학교 vs 회사
- 학교 : 논문 및 연구
- 회사 : 상품 및 서비스 생산
    - AI for service : AI는 보조 수단, 대부분의 회사가 해당
    - AI centric : AI로 가치 창출 (예: 테슬라)

## AI 팀
- AI 팀 구성
    - 비즈니스 : 기획자, 마케팅, 세일즈, PR, 법무, 윤리학자
    - 엔지니어링 : 데이터 엔지니어, AI 엔지니어, AIOps 엔지니어
        - 직무 상세 : https://fall2019.fullstackdeeplearning.com/course-content/ml-teams 

# 8. 박성준 (Upstage) - 자연어 처리를 위한 언어 모델의 학습과 평가
- 언어 모델링 : 주어진 문맥을 활용해 다음에 나타날 단어 예측
    - 양방향 언어 모델 BERT를 데이터셋에 fine-tuning하면 성능이 좋다.
    
- 언어 모델링 평가 : GLUE 벤치마크(언어 모델 평가를 위한 영어 벤치마크)
- KLUE : 한국어 자연어 이해 벤치마크
    - 개체명 인식(NamedEntity Recognition) : 이름, 지명 구분 인식
    - 품사 태깅 및 의존 구문 분석(POS tagging + Dependency Parsing) : 문장의 단어 의존 관계 파악
    - 문장 분류(Text classification)
    - 자연어 추론(Natural Language Inference) : 문장 간 의미 관계(모순,설명,관계없음)를 파악
    - 문장 유사도(Semantic Textual Similarity) : 문장 간 유사도 평가
    - 관계 추출(Relation Extraction) : 고난도, 문장에 등장하는 entity(독립체) 간 관계 파악
    - 질의 응답(Question & Answering) : 고난도, 질문에 대한 응답 적절도 평가
    - 목적형 대화(Task-oriented Dialogue) : 고난도, 사람 간 대화 패턴 속 유의미한 정보 추출 평가